{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOlagwkHER5vRLqLds+FqDu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksadowski13/GCN/blob/main/GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGGFCOukvkL2"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbwljV5ettzS"
      },
      "source": [
        "import random\r\n",
        "from random import choice, choices, randint\r\n",
        "from typing import Dict, List, Tuple\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import networkx as nx\r\n",
        "import pandas as pd\r\n",
        "import plotly.express as px\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from networkx.algorithms.community.modularity_max import \\\r\n",
        "    greedy_modularity_communities\r\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpK33L7Dxol0"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4CCvbbIgGOJ"
      },
      "source": [
        "def draw_graph(\r\n",
        "    graph: nx.Graph,\r\n",
        "    color_map: List[str] = None,\r\n",
        "    positions: Dict[int, Tuple[float, float]] = None,\r\n",
        "    axis_labels: Tuple[str, str] = None,\r\n",
        "    with_edges=True,\r\n",
        ") -> None:\r\n",
        "    fig, ax = plt.subplots(figsize=(13, 13))\r\n",
        "\r\n",
        "    nx.draw(\r\n",
        "        graph,\r\n",
        "        nx.spring_layout(graph) if positions is None else positions,\r\n",
        "        node_size=400,\r\n",
        "        node_color=color_map,\r\n",
        "        with_labels=True,\r\n",
        "        ax=ax,\r\n",
        "    )\r\n",
        "\r\n",
        "    if axis_labels is not None:\r\n",
        "        plt.axis('on')\r\n",
        "        ax.tick_params(left=True, bottom=True,\r\n",
        "                       labelleft=True, labelbottom=True)\r\n",
        "        plt.xlabel(axis_labels[0])\r\n",
        "        plt.ylabel(axis_labels[1])\r\n",
        "\r\n",
        "\r\n",
        "def create_graph() -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, nx.Graph]:\r\n",
        "    number_of_samples = 200\r\n",
        "    probability_of_edge = 0.03\r\n",
        "    seed = 13\r\n",
        "\r\n",
        "    random.seed(seed)\r\n",
        "\r\n",
        "    feature_range = {\r\n",
        "        0: {\r\n",
        "            0: (1, 3),\r\n",
        "            1: (1, 3),\r\n",
        "            2: (1, 10),\r\n",
        "            3: (1, 10),\r\n",
        "            4: (7, 10),\r\n",
        "            5: (4, 6),\r\n",
        "        },\r\n",
        "        1: {\r\n",
        "            0: (1, 5),\r\n",
        "            1: (6, 10),\r\n",
        "            2: (1, 3),\r\n",
        "            3: (1, 5),\r\n",
        "            4: (5, 10),\r\n",
        "            5: (1, 3),\r\n",
        "        },\r\n",
        "        2: {\r\n",
        "            0: (4, 7),\r\n",
        "            1: (1, 3),\r\n",
        "            2: (1, 10),\r\n",
        "            3: (4, 6),\r\n",
        "            4: (1, 3),\r\n",
        "            5: (1, 10),\r\n",
        "        },\r\n",
        "        3: {\r\n",
        "            0: (1, 2),\r\n",
        "            1: (2, 6),\r\n",
        "            2: (8, 10),\r\n",
        "            3: (8, 10),\r\n",
        "            4: (8, 10),\r\n",
        "            5: (4, 10),\r\n",
        "        },\r\n",
        "        4: {\r\n",
        "            0: (3, 8),\r\n",
        "            1: (4, 6),\r\n",
        "            2: (2, 5),\r\n",
        "            3: (1, 3),\r\n",
        "            4: (1, 4),\r\n",
        "            5: (1, 5),\r\n",
        "        },\r\n",
        "        4: {\r\n",
        "            0: (3, 8),\r\n",
        "            1: (4, 6),\r\n",
        "            2: (2, 5),\r\n",
        "            3: (1, 3),\r\n",
        "            4: (1, 4),\r\n",
        "            5: (1, 5),\r\n",
        "        },\r\n",
        "        5: {\r\n",
        "            0: (4, 7),\r\n",
        "            1: (5, 8),\r\n",
        "            2: (5, 8),\r\n",
        "            3: (7, 10),\r\n",
        "            4: (5, 10),\r\n",
        "            5: (3, 6),\r\n",
        "        },\r\n",
        "        6: {\r\n",
        "            0: (7, 10),\r\n",
        "            1: (9, 10),\r\n",
        "            2: (1, 4),\r\n",
        "            3: (1, 10),\r\n",
        "            4: (3, 10),\r\n",
        "            5: (6, 10),\r\n",
        "        },\r\n",
        "        7: {\r\n",
        "            0: (3, 8),\r\n",
        "            1: (7, 10),\r\n",
        "            2: (8, 10),\r\n",
        "            3: (5, 10),\r\n",
        "            4: (6, 10),\r\n",
        "            5: (1, 10),\r\n",
        "        },\r\n",
        "    }\r\n",
        "\r\n",
        "    graph = nx.fast_gnp_random_graph(\r\n",
        "        number_of_samples, probability_of_edge, seed=seed)\r\n",
        "\r\n",
        "    communities = list(greedy_modularity_communities(graph))\r\n",
        "\r\n",
        "    features = [[] for _ in range(number_of_samples)]\r\n",
        "    labels = [[] for _ in range(number_of_samples)]\r\n",
        "\r\n",
        "    for community in range(len(communities)):\r\n",
        "        community_features = feature_range[community]\r\n",
        "        label = 0 if community in [0, 1, 2, 4] else 1\r\n",
        "\r\n",
        "        for v in communities[community]:\r\n",
        "            features[v] = [\r\n",
        "                randint(community_features[0][0], community_features[0][1]),\r\n",
        "                randint(community_features[1][0], community_features[1][1]),\r\n",
        "                randint(community_features[2][0], community_features[2][1]),\r\n",
        "                randint(community_features[3][0], community_features[3][1]),\r\n",
        "                randint(community_features[4][0], community_features[4][1]),\r\n",
        "                randint(community_features[5][0], community_features[5][1]),\r\n",
        "            ]\r\n",
        "            labels[v] = choices(\r\n",
        "                [0, 1] if label == 0 else [1, 0], cum_weights=[95, 5])[0]\r\n",
        "\r\n",
        "    indexes = list(range(number_of_samples))\r\n",
        "    train_indexes = []\r\n",
        "\r\n",
        "    while len(set(train_indexes)) <= 50:\r\n",
        "        train_indexes.append(choice(indexes))\r\n",
        "\r\n",
        "    train_indexes = list(set(train_indexes))\r\n",
        "\r\n",
        "    features = torch.Tensor(features) / 10\r\n",
        "\r\n",
        "    train_labels = torch.tensor([[labels[i], i]\r\n",
        "                                 for i in train_indexes], dtype=torch.long)\r\n",
        "    validation_labels = torch.tensor(labels, dtype=torch.long)\r\n",
        "\r\n",
        "    adjacency_matrix = torch.from_numpy(nx.to_numpy_matrix(graph))\r\n",
        "\r\n",
        "    return features, train_labels, validation_labels, adjacency_matrix, graph"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po-Y0tN5xwiR"
      },
      "source": [
        "# Dataset\r\n",
        "\r\n",
        "### Number of customers: 200\r\n",
        "\r\n",
        "### Features:\r\n",
        "0. Number of dogs\r\n",
        "1. Level of love for dogs\r\n",
        "2. Wealth of customer\r\n",
        "3. Healthy eating awareness of customer\r\n",
        "4. Size of the city of residance\r\n",
        "5. Age of the customer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oreO0-YxyoT"
      },
      "source": [
        "features, train_labels, validation_labels, adjacency_matrix, G = create_graph()\r\n",
        "\r\n",
        "colors = ['gray', 'purple']\r\n",
        "color_map_train = ['red' for _ in range(200)]\r\n",
        "color_map = [colors[i] for i in validation_labels]\r\n",
        "\r\n",
        "for i in train_labels:\r\n",
        "    color_map_train[i[1]] = colors[i[0]]\r\n",
        "\r\n",
        "draw_graph(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpp9IsjMqp3z"
      },
      "source": [
        "## Graph with train labels\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "* Gray - Junk Dog Food\r\n",
        "* Purple - Premium Dog Food\r\n",
        "* Red - (?) not specified\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkpHsPJ7rL0G"
      },
      "source": [
        "draw_graph(G, color_map_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9vViiEJ4UmK"
      },
      "source": [
        "## Graph with ground truth labels (validation)\r\n",
        "* Gray - Junk Dog Food\r\n",
        "* Purple - Premium Dog Food"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnqaBCR9DH9m"
      },
      "source": [
        "draw_graph(G, color_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAWRAxYbO7dS"
      },
      "source": [
        "## Relationship between **'level of love for dogs'** and **'wealth of customer'**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oErBJQxhKhph"
      },
      "source": [
        "positions = {i: (features[i, 1], features[i, 2]) for i in range(len(features))}\r\n",
        "\r\n",
        "draw_graph(G, color_map, positions, axis_labels=('love', 'wealth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T8w80lBO_K9"
      },
      "source": [
        "## Relationship between **'number of dogs'** and **'age of customer'**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlZ6UVm4O532"
      },
      "source": [
        "positions = {i: (features[i, 0], features[i, 5]) for i in range(len(features))}\r\n",
        "\r\n",
        "draw_graph(\r\n",
        "    G, color_map, positions, axis_labels=('number of dogs', 'age of customer'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOxCZqVuPWu9"
      },
      "source": [
        "## Relationship between **'size of the city of residence'** and **'healthy eating awareness of customer'**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGey8fZFS9S7"
      },
      "source": [
        "positions = {i: (features[i, 3], features[i, 4]) for i in range(len(features))}\r\n",
        "\r\n",
        "draw_graph(G, color_map, positions, axis_labels=(\r\n",
        "    'city size', 'healthy eating'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn0Oy_v2d_vu"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M9cik63uWVN"
      },
      "source": [
        "class GraphConv(nn.Module):\r\n",
        "    def __init__(\r\n",
        "        self,\r\n",
        "        input_features: int,\r\n",
        "        output_features: int,\r\n",
        "        weight=True,\r\n",
        "        bias=True,\r\n",
        "    ):\r\n",
        "        super(GraphConv, self).__init__()\r\n",
        "        self._input_features = input_features\r\n",
        "        self._output_features = output_features\r\n",
        "        self.weight = nn.Parameter(\r\n",
        "            torch.Tensor(input_features, output_features))\r\n",
        "        self.bias = nn.Parameter(torch.Tensor(output_features))\r\n",
        "        self.reset_parameters()\r\n",
        "\r\n",
        "    def reset_parameters(self) -> None:\r\n",
        "        if self.weight is not None:\r\n",
        "            nn.init.xavier_uniform_(self.weight)\r\n",
        "\r\n",
        "        if self.bias is not None:\r\n",
        "            nn.init.zeros_(self.bias)\r\n",
        "\r\n",
        "    def forward(\r\n",
        "        self,\r\n",
        "        inputs: torch.Tensor,\r\n",
        "        adjacency_matrix: torch.Tensor,\r\n",
        "    ) -> torch.Tensor:\r\n",
        "        A_hat = adjacency_matrix + torch.diag(adjacency_matrix)\r\n",
        "        D_hat = torch.diag(torch.sum(A_hat, 1, keepdim=False))\r\n",
        "        D_hat_inv_sqrt = torch.inverse(torch.sqrt(D_hat))\r\n",
        "\r\n",
        "        # D_hat_inv_sqrt @ A_hat @ D_hat_inv_sqrt @ features @ weights + bias\r\n",
        "        A_sym = D_hat_inv_sqrt @ A_hat @ D_hat_inv_sqrt\r\n",
        "        message_passing = A_sym @ inputs\r\n",
        "        x = message_passing @ self.weight + self.bias\r\n",
        "\r\n",
        "        return x"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5Q_m3m82JhN"
      },
      "source": [
        "class GCN(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(GCN, self).__init__()\r\n",
        "        self._graph_conv_1 = GraphConv(6, 4)\r\n",
        "        self._activation_1 = nn.ReLU()\r\n",
        "        self._graph_conv_2 = GraphConv(4, 2)\r\n",
        "        self._activation_2 = nn.LogSoftmax(dim=1)\r\n",
        "\r\n",
        "    def forward(\r\n",
        "        self, \r\n",
        "        inputs: torch.Tensor, \r\n",
        "        adjacency_matrix: torch.Tensor,\r\n",
        "    ) -> None:\r\n",
        "        x = self._graph_conv_1(inputs, adjacency_matrix)\r\n",
        "        x = self._activation_1(x)\r\n",
        "        x = self._graph_conv_2(x, adjacency_matrix)\r\n",
        "        x = self._activation_2(x)\r\n",
        "\r\n",
        "        return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6Xrbsb_1NJ5"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD3aZywnP-3_"
      },
      "source": [
        "def train(\r\n",
        "    model: nn.Module,\r\n",
        "    features: torch.Tensor,\r\n",
        "    train_labels: torch.Tensor,\r\n",
        "    validation_labels: torch.Tensor,\r\n",
        "    adjacency_matrix: torch.Tensor,\r\n",
        "    epochs: int,\r\n",
        ") -> pd.DataFrame:\r\n",
        "    metrics = []\r\n",
        "\r\n",
        "    with tqdm(total=epochs) as pbar:\r\n",
        "        for epoch in range(epochs):\r\n",
        "            # training phase\r\n",
        "            model.train()\r\n",
        "            optimizer.zero_grad()\r\n",
        "\r\n",
        "            output = model(features.double(), adjacency_matrix.double())\r\n",
        "            train_output = torch.index_select(output, 0, train_labels[:, 1])\r\n",
        "\r\n",
        "            train_loss = F.nll_loss(train_output, train_labels[:, 0])\r\n",
        "            train_accuracy = torch.sum(torch.argmax(\r\n",
        "                train_output, dim=1) == train_labels[:, 0]).item() * 100.0 / len(train_output)\r\n",
        "\r\n",
        "            train_loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            metrics.append(['train', 'loss', epoch + 1, train_loss.item()])\r\n",
        "            metrics.append(['train', 'accuracy', epoch + 1, train_accuracy])\r\n",
        "\r\n",
        "            # validation phase\r\n",
        "            model.eval()\r\n",
        "\r\n",
        "            validation_loss = F.nll_loss(output, validation_labels)\r\n",
        "            validation_accuracy = torch.sum(torch.argmax(\r\n",
        "                output, dim=1) == validation_labels).item() * 100.0 / len(output)\r\n",
        "\r\n",
        "            metrics.append(['validation', 'loss', epoch +\r\n",
        "                            1, validation_loss.item()])\r\n",
        "            metrics.append(['validation', 'accuracy',\r\n",
        "                            epoch + 1, validation_accuracy])\r\n",
        "\r\n",
        "            if (epoch + 1) % 100 == 0:\r\n",
        "                print(\r\n",
        "                    f'Epoch: {epoch + 1:4} '\r\n",
        "                    f'Train Loss: {round(train_loss.item(), 4):.4f} '\r\n",
        "                    f'Validation Loss: {round(validation_loss.item(), 4):.4f} '\r\n",
        "                    f'Train Accuracy: {round(train_accuracy, 2):.2f} '\r\n",
        "                    f'Validation Accuracy: {round(validation_accuracy, 2):.2f}'\r\n",
        "                )\r\n",
        "\r\n",
        "            pbar.update(1)\r\n",
        "\r\n",
        "    df = pd.DataFrame(metrics, columns=['phase', 'metric', 'epoch', 'value'])\r\n",
        "\r\n",
        "    fig = px.line(\r\n",
        "        df,\r\n",
        "        x='epoch',\r\n",
        "        y='value',\r\n",
        "        color='phase',\r\n",
        "        facet_col='metric',\r\n",
        "        facet_col_wrap=1,\r\n",
        "        template='plotly_dark',\r\n",
        "        width=800,\r\n",
        "    )\r\n",
        "    fig.update_yaxes(matches=None)\r\n",
        "    fig.update_yaxes(showticklabels=True, col=2)\r\n",
        "    fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[-1]))\r\n",
        "    fig.show()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLaQ-PiJyMi3"
      },
      "source": [
        "# seed is set for repeatability of results for presentation purposes\r\n",
        "torch.manual_seed(13)\r\n",
        "\r\n",
        "EPOCHS = 3000\r\n",
        "\r\n",
        "model = GCN().double()\r\n",
        "optimizer = torch.optim.Adam(model.parameters())\r\n",
        "\r\n",
        "train(model, features, train_labels, validation_labels, adjacency_matrix, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XexqPfdc6U-I"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBY1d0UjISS_"
      },
      "source": [
        "model.eval()\r\n",
        "\r\n",
        "outputs = model(features.double(), adjacency_matrix.double())\r\n",
        "outputs_arg_max = torch.argmax(outputs, dim=1)\r\n",
        "\r\n",
        "positions = {\r\n",
        "    i: (outputs_arg_max[i], outputs[i, outputs_arg_max[i]]) for i in range(200)}\r\n",
        "\r\n",
        "draw_graph(G, color_map, positions, axis_labels=('junk, premium', 'certainty'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}